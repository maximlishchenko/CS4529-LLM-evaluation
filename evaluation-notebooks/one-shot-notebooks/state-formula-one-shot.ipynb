{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.7a\n",
    "\n",
    "Prompt type: one-shot\n",
    "\n",
    "Task: for a trace, state the formula that was used to get to the final emission score. Use labels as entity names and \n",
    "conversion factor IDs as their values.\n",
    "\n",
    "Given as example: smli_trace1_valid\n",
    "\n",
    "Given as task: smli_trace3_def\n",
    "\n",
    "Expect to see in response:\n",
    "\n",
    "One of the following:\n",
    "1. ((Watt Consumption * Duration of use) / 1000) * \"https://w3id.org/ecfkg/i/mlco2/aws/cn-north-1/cf\"\n",
    "2. ((Watt Consumption * Duration of use) / 1000) * 0.68\n",
    "\n",
    "Quantified as: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required utility functions\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from utils import utils, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking by BM25...: 100%|██████████| 1/1 [00:00<00:00, 477.28 docs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['((Watt Consumption * Duration of Use) / 1000) * 0.68']\n"
     ]
    }
   ],
   "source": [
    "traces_to_process = ['smli_trace3_def']\n",
    "document_store = utils.build_document_store(traces_to_process)\n",
    "\n",
    "prompt_template = utils.read_prompt(constants.ONE_SHOT_TEMPLATES_DIR, 'state-formula-one-shot-template.txt')\n",
    "\n",
    "question = 'State the formula that was used to get to the final emission score. Use labels as entity names and conversion factor IDs as their values.'\n",
    "\n",
    "utils.build_pipeline(document_store, prompt_template, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.7b\n",
    "\n",
    "Prompt type: one-shot\n",
    "\n",
    "Task: for a trace, state the formula that was used to get to the final emission score. Use labels as entity names and \n",
    "conversion factor IDs as their values.\n",
    "\n",
    "Given as example: smli_trace1_valid\n",
    "\n",
    "Given as task: water_trace_valid\n",
    "\n",
    "Expect to see in response:\n",
    "\n",
    "One of the following:\n",
    "1. https://water.com/provenance/cf * Litres of water used per litre of beer\n",
    "2. 0.149 * Litres of water used per litre of beer\n",
    "\n",
    "Quantified as: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking by BM25...: 100%|██████████| 1/1 [00:00<00:00, 321.87 docs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['((Litres of water used per litre of beer) * https://water.com/provenance/cf)']\n"
     ]
    }
   ],
   "source": [
    "traces_to_process = ['water_trace_valid']\n",
    "document_store = utils.build_document_store(traces_to_process)\n",
    "\n",
    "prompt_template = utils.read_prompt(constants.ONE_SHOT_TEMPLATES_DIR, 'state-formula-one-shot-template.txt')\n",
    "\n",
    "question = 'State the formula that was used to get to the final emission score. Use labels as entity names and conversion factor IDs as their values.'\n",
    "\n",
    "utils.build_pipeline(document_store, prompt_template, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.7c\n",
    "\n",
    "Prompt type: one-shot\n",
    "\n",
    "Task: for a trace, state the formula that was used to get to the final emission score. Use labels as entity names and \n",
    "conversion factor IDs as their values.\n",
    "\n",
    "Given as example: smli_trace1_valid\n",
    "\n",
    "Given as task: fleet_vehicles_trace_sensor\n",
    "\n",
    "Expect to see in response:\n",
    "\n",
    "One of the following:\n",
    "1. https://fleetvehicles.com/provenance/cf * Fuel used by vehicles\n",
    "2. 2.5206 * Fuel used by vehicles\n",
    "\n",
    "Quantified as: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking by BM25...: 100%|██████████| 1/1 [00:00<00:00, 345.32 docs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['( Fuel used by vehicles * 2.5206)']\n"
     ]
    }
   ],
   "source": [
    "traces_to_process = ['fleet_vehicles_trace_sensor']\n",
    "document_store = utils.build_document_store(traces_to_process)\n",
    "\n",
    "prompt_template = utils.read_prompt(constants.ONE_SHOT_TEMPLATES_DIR, 'state-formula-one-shot-template.txt')\n",
    "\n",
    "question = 'State the formula that was used to get to the final emission score. Use labels as entity names and conversion factor IDs as their values.'\n",
    "\n",
    "utils.build_pipeline(document_store, prompt_template, question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
